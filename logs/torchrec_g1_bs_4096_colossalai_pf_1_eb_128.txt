torchx 2022-09-30 14:33:05 INFO     Log directory is: log/torchrec_synth/g1_bs_4096_colossalai_pf_1_eb_128
torchx 2022-09-30 14:33:05 INFO     Waiting for the app to finish...
dlrm_main/0 bash: /opt/lcsoftware/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-9.3.0/miniconda3-4.10.3-u6p3tgreee7aigtnvuhr44yqo7vcg6r6/lib/libtinfo.so.6: no version information available (required by bash)
dlrm_main/0 [0]:Colossalai should be built with cuda extension to use the FP16 optimizer
dlrm_main/0 [0]:If you want to activate cuda mode for MoE, please install with cuda_ext!
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_10.pt
dlrm_main/0 [0]:colossalai - torch.distributed.distributed_c10d - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
dlrm_main/0 [0]:colossalai - torch.distributed.distributed_c10d - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_7.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_15.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_4.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_8.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_9.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_13.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_14.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_0.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_2.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_1.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_5.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_6.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_12.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_3.pt
dlrm_main/0 [0]:load file:  /data/scratch/RecSys/embedding_bag/fbgemm_t856_bs65536_11.pt
dlrm_main/0 [0]:Namespace(kaggle=True, profile_dir='', memory_fraction=None, epochs=1, batch_size=4096, limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, dataset_name='criteo_1t', num_embeddings=None, num_embeddings_per_feature=[8015999, 9997799, 6138289, 21886, 204008, 6148, 282795, 1316, 3639992, 319, 3394206, 12203324, 4091851, 11641, 4657566], dense_arch_layer_sizes='512,256,128', over_arch_layer_sizes='1024,1024,512,256,1', embedding_dim=128, undersampling_rate=None, seed=None, pin_memory=True, eval_acc=False, mmap_mode=None, in_memory_binary_criteo_path='/data/scratch/RecSys/embedding_bag', learning_rate=1.0, shuffle_batches=True, validation_freq_within_epoch=None, change_lr=None, lr_change_point=0.8, lr_after_change_point=0.2, adagrad=False, sharder_type='colossalai', prefetch_num=1)
dlrm_main/0 [0]:training batches: 256, val batches: 0, test batches: 0
dlrm_main/0 [0]:After model init:  GPU memory allocated: 0.01 GB, GPU memory reserved: 0.02 GB, CPU memory usage: 33.61 GB
dlrm_main/0 [0]:DLRM: 6,743,520,001.
dlrm_main/0 [0]:Number of model parameters: 6,743,520,001, storage overhead: 25.12 GB. Number of model buffers: 240, storage overhead: 0.00 GB.
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: ########################################################################################################################################################################################
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                                              --- Planner Statistics ---                                                                              #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                      --- Evalulated 1 proposal(s), found 1 possible plan(s), ran for 0.01s ---                                                       #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #      Rank     HBM (GB)     DDR (GB)     Perf (ms)     Input (MB)     Output (MB)     Shards                                                                                          #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #    ------   ----------   ----------   -----------   ------------   -------------   --------                                                                                          #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #         0     0.1 (0%)    25.1 (3%)         0.493           0.47            30.0     CW: 15                                                                                          #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                                                                                                                                                      #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: # Input: MB/iteration, Output: MB/iteration, Shards: number of tables                                                                                                                  #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: # HBM: estimated peak memory usage for shards, dense tensors, and features (KJT)                                                                                                       #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                                                                                                                                                      #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: # Parameter Info:                                                                                                                                                                      #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                    FQN     Sharding     Compute Kernel     Perf (ms)     Pooling Factor     Output     Features    Emb Dim     Hash Size     Ranks   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                  -----   ----------   ----------------   -----------   ----------------   --------   ----------   --------   -----------   -------   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #     model.sparse_arch.embedding_bag_collection.t_cat_0           CW   colossalai_batch         0.033                1.0     pooled            1        128       8015999         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #     model.sparse_arch.embedding_bag_collection.t_cat_1           CW   colossalai_batch         0.033                1.0     pooled            1        128       9997799         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #     model.sparse_arch.embedding_bag_collection.t_cat_2           CW   colossalai_batch         0.033                1.0     pooled            1        128       6138289         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #     model.sparse_arch.embedding_bag_collection.t_cat_3           CW   colossalai_batch         0.033                1.0     pooled            1        128         21886         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #     model.sparse_arch.embedding_bag_collection.t_cat_4           CW   colossalai_batch         0.033                1.0     pooled            1        128        204008         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #     model.sparse_arch.embedding_bag_collection.t_cat_5           CW   colossalai_batch         0.033                1.0     pooled            1        128          6148         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #     model.sparse_arch.embedding_bag_collection.t_cat_6           CW   colossalai_batch         0.033                1.0     pooled            1        128        282795         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #     model.sparse_arch.embedding_bag_collection.t_cat_7           CW   colossalai_batch         0.033                1.0     pooled            1        128          1316         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #     model.sparse_arch.embedding_bag_collection.t_cat_8           CW   colossalai_batch         0.033                1.0     pooled            1        128       3639992         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #     model.sparse_arch.embedding_bag_collection.t_cat_9           CW   colossalai_batch         0.033                1.0     pooled            1        128           319         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #    model.sparse_arch.embedding_bag_collection.t_cat_10           CW   colossalai_batch         0.033                1.0     pooled            1        128       3394206         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #    model.sparse_arch.embedding_bag_collection.t_cat_11           CW   colossalai_batch         0.033                1.0     pooled            1        128      12203324         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #    model.sparse_arch.embedding_bag_collection.t_cat_12           CW   colossalai_batch         0.033                1.0     pooled            1        128       4091851         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #    model.sparse_arch.embedding_bag_collection.t_cat_13           CW   colossalai_batch         0.033                1.0     pooled            1        128         11641         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #    model.sparse_arch.embedding_bag_collection.t_cat_14           CW   colossalai_batch         0.033                1.0     pooled            1        128       4657566         0   #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                                                                                                                                                      #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: # Batch Size: 4096                                                                                                                                                                     #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                                                                                                                                                      #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: # Compute Kernels:                                                                                                                                                                     #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #    colossalai_batch: 15                                                                                                                                                              #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                                                                                                                                                      #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: # Longest Critical Path: 0.493 ms on rank 0                                                                                                                                            #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                                                                                                                                                      #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: # Peak Memory Pressure: 0.086 GB on rank 0                                                                                                                                             #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                                                                                                                                                      #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: # Usable Memory:                                                                                                                                                                       #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #    HBM: 68.0 GB, DDR: 850.0 GB                                                                                                                                                       #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #    Percent of Total: 85%                                                                                                                                                             #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                                                                                                                                                      #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: # Dense Storage (per rank):                                                                                                                                                            #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #    HBM: 0.048 GB, DDR: 0.0 GB                                                                                                                                                        #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #                                                                                                                                                                                      #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: # KJT Storage (per rank):                                                                                                                                                              #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: #    HBM: 0.009 GB, DDR: 0.0 GB                                                                                                                                                        #
dlrm_main/0 [0]:colossalai - torchrec.distributed.planner.stats - INFO: ########################################################################################################################################################################################
dlrm_main/0 [0]:Cache warmup finished cost 0.0487550740072038 sec.
dlrm_main/0 [0]:After model parallel:  GPU memory allocated: 1.06 GB, GPU memory reserved: 1.24 GB, CPU memory usage: 65.69 GB
dlrm_main/0 [0]:Plan: {'model.sparse_arch.embedding_bag_collection': {'t_cat_0': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[8015999, 128], placement=rank:0/cuda:0)])), 't_cat_1': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[9997799, 128], placement=rank:0/cuda:0)])), 't_cat_2': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[6138289, 128], placement=rank:0/cuda:0)])), 't_cat_3': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[21886, 128], placement=rank:0/cuda:0)])), 't_cat_4': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[204008, 128], placement=rank:0/cuda:0)])), 't_cat_5': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[6148, 128], placement=rank:0/cuda:0)])), 't_cat_6': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[282795, 128], placement=rank:0/cuda:0)])), 't_cat_7': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[1316, 128], placement=rank:0/cuda:0)])), 't_cat_8': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[3639992, 128], placement=rank:0/cuda:0)])), 't_cat_9': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[319, 128], placement=rank:0/cuda:0)])), 't_cat_10': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[3394206, 128], placement=rank:0/cuda:0)])), 't_cat_11': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[12203324, 128], placement=rank:0/cuda:0)])), 't_cat_12': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[4091851, 128], placement=rank:0/cuda:0)])), 't_cat_13': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[11641, 128], placement=rank:0/cuda:0)])), 't_cat_14': ParameterSharding(sharding_type='column_wise', compute_kernel='colossalai_batch', ranks=[0], sharding_spec=EnumerableShardingSpec(shards=[ShardMetadata(shard_offsets=[0, 0], shard_sizes=[4657566, 128], placement=rank:0/cuda:0)]))}}
dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   0%|          | 0/256.0 [00:00<?, ?it/s]dlrm_main/0 [0]:colossalai - torchrec.distributed.train_pipeline - INFO: Module 'model.sparse_arch.embedding_bag_collection'' will be pipelined
dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   0%|          | 1/256.0 [00:02<11:17,  2.66s/it]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   1%|          | 2/256.0 [00:04<08:05,  1.91s/it]dlrm_main/0 [0]:colossalai - torch.nn.parallel.distributed - INFO: Reducer buckets have been rebuilt in this iteration.
dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   1%|          | 3/256.0 [00:04<05:00,  1.19s/it]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   2%|▏         | 4/256.0 [00:04<03:34,  1.17it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   2%|▏         | 5/256.0 [00:05<02:43,  1.53it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   2%|▏         | 6/256.0 [00:05<02:14,  1.85it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   3%|▎         | 7/256.0 [00:05<01:57,  2.13it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   3%|▎         | 8/256.0 [00:05<01:45,  2.34it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   4%|▎         | 9/256.0 [00:06<01:39,  2.48it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   4%|▍         | 10/256.0 [00:06<01:34,  2.61it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   4%|▍         | 11/256.0 [00:07<01:30,  2.69it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   5%|▍         | 12/256.0 [00:07<01:27,  2.78it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   5%|▌         | 13/256.0 [00:07<01:26,  2.80it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   5%|▌         | 14/256.0 [00:08<01:26,  2.79it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   6%|▌         | 15/256.0 [00:08<01:26,  2.80it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   6%|▋         | 16/256.0 [00:08<01:24,  2.83it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   7%|▋         | 17/256.0 [00:09<01:23,  2.87it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   7%|▋         | 18/256.0 [00:09<01:19,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   7%|▋         | 19/256.0 [00:09<01:18,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   8%|▊         | 20/256.0 [00:10<01:17,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   8%|▊         | 21/256.0 [00:10<01:17,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   9%|▊         | 22/256.0 [00:10<01:17,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   9%|▉         | 23/256.0 [00:11<01:16,  3.06it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:   9%|▉         | 24/256.0 [00:11<01:16,  3.05it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  10%|▉         | 25/256.0 [00:11<01:18,  2.93it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  10%|█         | 26/256.0 [00:12<01:19,  2.90it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  11%|█         | 27/256.0 [00:12<01:18,  2.93it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  11%|█         | 28/256.0 [00:12<01:18,  2.92it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  11%|█▏        | 29/256.0 [00:13<01:17,  2.93it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  12%|█▏        | 30/256.0 [00:13<01:14,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  12%|█▏        | 31/256.0 [00:13<01:14,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  12%|█▎        | 32/256.0 [00:14<01:13,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  13%|█▎        | 33/256.0 [00:14<01:13,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  13%|█▎        | 34/256.0 [00:14<01:13,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  14%|█▎        | 35/256.0 [00:15<01:13,  3.00it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  14%|█▍        | 36/256.0 [00:15<01:13,  2.98it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  14%|█▍        | 37/256.0 [00:15<01:13,  3.00it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  15%|█▍        | 38/256.0 [00:16<01:12,  2.99it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  15%|█▌        | 39/256.0 [00:16<01:12,  2.98it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  16%|█▌        | 40/256.0 [00:16<01:12,  2.99it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  16%|█▌        | 41/256.0 [00:17<01:11,  2.99it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  16%|█▋        | 42/256.0 [00:17<01:09,  3.08it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  17%|█▋        | 43/256.0 [00:17<01:09,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  17%|█▋        | 44/256.0 [00:18<01:09,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  18%|█▊        | 45/256.0 [00:18<01:19,  2.64it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  18%|█▊        | 46/256.0 [00:18<01:17,  2.71it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  18%|█▊        | 47/256.0 [00:19<01:15,  2.76it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  19%|█▉        | 48/256.0 [00:19<01:14,  2.79it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  19%|█▉        | 49/256.0 [00:19<01:12,  2.86it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  20%|█▉        | 50/256.0 [00:20<01:11,  2.90it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  20%|█▉        | 51/256.0 [00:20<01:09,  2.93it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  20%|██        | 52/256.0 [00:20<01:09,  2.94it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  21%|██        | 53/256.0 [00:21<01:08,  2.96it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  21%|██        | 54/256.0 [00:21<01:06,  3.05it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  21%|██▏       | 55/256.0 [00:21<01:06,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  22%|██▏       | 56/256.0 [00:22<01:07,  2.97it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  22%|██▏       | 57/256.0 [00:22<01:06,  2.99it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  23%|██▎       | 58/256.0 [00:22<01:06,  2.98it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  23%|██▎       | 59/256.0 [00:23<01:05,  2.99it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  23%|██▎       | 60/256.0 [00:23<01:05,  2.98it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  24%|██▍       | 61/256.0 [00:23<01:05,  2.97it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  24%|██▍       | 62/256.0 [00:24<01:05,  2.96it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  25%|██▍       | 63/256.0 [00:24<01:05,  2.94it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  25%|██▌       | 64/256.0 [00:24<01:05,  2.94it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  25%|██▌       | 65/256.0 [00:25<01:04,  2.97it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  26%|██▌       | 66/256.0 [00:25<01:01,  3.07it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  26%|██▌       | 67/256.0 [00:25<01:01,  3.08it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  27%|██▋       | 68/256.0 [00:26<01:01,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  27%|██▋       | 69/256.0 [00:26<01:01,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  27%|██▋       | 70/256.0 [00:26<01:01,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  28%|██▊       | 71/256.0 [00:27<01:02,  2.96it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  28%|██▊       | 72/256.0 [00:27<01:01,  3.00it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  29%|██▊       | 73/256.0 [00:27<01:00,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  29%|██▉       | 74/256.0 [00:28<00:59,  3.06it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  29%|██▉       | 75/256.0 [00:28<00:58,  3.08it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  30%|██▉       | 76/256.0 [00:28<00:58,  3.09it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  30%|███       | 77/256.0 [00:29<00:57,  3.09it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  30%|███       | 78/256.0 [00:29<00:55,  3.21it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  31%|███       | 79/256.0 [00:29<00:55,  3.17it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  31%|███▏      | 80/256.0 [00:30<00:56,  3.14it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  32%|███▏      | 81/256.0 [00:30<00:56,  3.09it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  32%|███▏      | 82/256.0 [00:30<00:56,  3.07it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  32%|███▏      | 83/256.0 [00:31<00:56,  3.07it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  33%|███▎      | 84/256.0 [00:31<00:56,  3.06it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  33%|███▎      | 85/256.0 [00:31<00:56,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  34%|███▎      | 86/256.0 [00:32<00:56,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  34%|███▍      | 87/256.0 [00:32<00:55,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  34%|███▍      | 88/256.0 [00:32<00:54,  3.06it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  35%|███▍      | 89/256.0 [00:33<00:54,  3.06it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  35%|███▌      | 90/256.0 [00:33<00:52,  3.17it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  36%|███▌      | 91/256.0 [00:33<00:52,  3.14it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  36%|███▌      | 92/256.0 [00:34<00:53,  3.06it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  36%|███▋      | 93/256.0 [00:34<00:53,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  37%|███▋      | 94/256.0 [00:34<00:53,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  37%|███▋      | 95/256.0 [00:35<00:53,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  38%|███▊      | 96/256.0 [00:35<00:52,  3.05it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  38%|███▊      | 97/256.0 [00:35<00:51,  3.08it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  38%|███▊      | 98/256.0 [00:36<00:50,  3.12it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  39%|███▊      | 99/256.0 [00:36<00:50,  3.11it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  39%|███▉      | 100/256.0 [00:36<00:50,  3.11it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  39%|███▉      | 101/256.0 [00:36<00:50,  3.10it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  40%|███▉      | 102/256.0 [00:37<00:48,  3.20it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  40%|████      | 103/256.0 [00:37<00:48,  3.19it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  41%|████      | 104/256.0 [00:37<00:47,  3.18it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  41%|████      | 105/256.0 [00:38<00:47,  3.18it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  41%|████▏     | 106/256.0 [00:38<00:47,  3.17it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  42%|████▏     | 107/256.0 [00:38<00:47,  3.14it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  42%|████▏     | 108/256.0 [00:39<00:47,  3.11it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  43%|████▎     | 109/256.0 [00:39<00:47,  3.11it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  43%|████▎     | 110/256.0 [00:39<00:47,  3.10it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  43%|████▎     | 111/256.0 [00:40<00:46,  3.13it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  44%|████▍     | 112/256.0 [00:40<00:45,  3.13it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  44%|████▍     | 113/256.0 [00:40<00:45,  3.12it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  45%|████▍     | 114/256.0 [00:41<00:44,  3.21it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  45%|████▍     | 115/256.0 [00:41<00:56,  2.51it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  45%|████▌     | 116/256.0 [00:42<00:52,  2.65it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  46%|████▌     | 117/256.0 [00:42<00:50,  2.76it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  46%|████▌     | 118/256.0 [00:42<00:48,  2.85it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  46%|████▋     | 119/256.0 [00:42<00:47,  2.89it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  47%|████▋     | 120/256.0 [00:43<00:46,  2.93it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  47%|████▋     | 121/256.0 [00:43<00:45,  2.94it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  48%|████▊     | 122/256.0 [00:43<00:45,  2.98it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  48%|████▊     | 123/256.0 [00:44<00:44,  2.99it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  48%|████▊     | 124/256.0 [00:44<00:44,  2.98it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  49%|████▉     | 125/256.0 [00:44<00:43,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  49%|████▉     | 126/256.0 [00:45<00:42,  3.08it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  50%|████▉     | 127/256.0 [00:45<00:41,  3.07it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  50%|█████     | 128/256.0 [00:45<00:41,  3.05it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  50%|█████     | 129/256.0 [00:46<00:41,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  51%|█████     | 130/256.0 [00:46<00:41,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  51%|█████     | 131/256.0 [00:46<00:41,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  52%|█████▏    | 132/256.0 [00:47<00:41,  2.97it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  52%|█████▏    | 133/256.0 [00:47<00:41,  2.98it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  52%|█████▏    | 134/256.0 [00:47<00:40,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  53%|█████▎    | 135/256.0 [00:48<00:40,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  53%|█████▎    | 136/256.0 [00:48<00:39,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  54%|█████▎    | 137/256.0 [00:48<00:39,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  54%|█████▍    | 138/256.0 [00:49<00:38,  3.08it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  54%|█████▍    | 139/256.0 [00:49<00:38,  3.05it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  55%|█████▍    | 140/256.0 [00:49<00:38,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  55%|█████▌    | 141/256.0 [00:50<00:38,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  55%|█████▌    | 142/256.0 [00:50<00:37,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  56%|█████▌    | 143/256.0 [00:50<00:37,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  56%|█████▋    | 144/256.0 [00:51<00:36,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  57%|█████▋    | 145/256.0 [00:51<00:36,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  57%|█████▋    | 146/256.0 [00:51<00:36,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  57%|█████▋    | 147/256.0 [00:52<00:35,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  58%|█████▊    | 148/256.0 [00:52<00:35,  3.00it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  58%|█████▊    | 149/256.0 [00:52<00:35,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  59%|█████▊    | 150/256.0 [00:53<00:35,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  59%|█████▉    | 151/256.0 [00:53<00:33,  3.12it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  59%|█████▉    | 152/256.0 [00:53<00:33,  3.09it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  60%|█████▉    | 153/256.0 [00:54<00:33,  3.06it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  60%|██████    | 154/256.0 [00:54<00:33,  3.05it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  61%|██████    | 155/256.0 [00:54<00:33,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  61%|██████    | 156/256.0 [00:55<00:33,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  61%|██████▏   | 157/256.0 [00:55<00:32,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  62%|██████▏   | 158/256.0 [00:55<00:32,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  62%|██████▏   | 159/256.0 [00:56<00:32,  3.00it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  62%|██████▎   | 160/256.0 [00:56<00:32,  2.99it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  63%|██████▎   | 161/256.0 [00:56<00:32,  2.94it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  63%|██████▎   | 162/256.0 [00:57<00:32,  2.89it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  64%|██████▎   | 163/256.0 [00:57<00:31,  2.99it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  64%|██████▍   | 164/256.0 [00:57<00:30,  2.97it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  64%|██████▍   | 165/256.0 [00:58<00:30,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  65%|██████▍   | 166/256.0 [00:58<00:29,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  65%|██████▌   | 167/256.0 [00:58<00:29,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  66%|██████▌   | 168/256.0 [00:59<00:28,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  66%|██████▌   | 169/256.0 [00:59<00:28,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  66%|██████▋   | 170/256.0 [00:59<00:28,  3.00it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  67%|██████▋   | 171/256.0 [01:00<00:28,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  67%|██████▋   | 172/256.0 [01:00<00:27,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  68%|██████▊   | 173/256.0 [01:00<00:27,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  68%|██████▊   | 174/256.0 [01:01<00:27,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  68%|██████▊   | 175/256.0 [01:01<00:26,  3.10it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  69%|██████▉   | 176/256.0 [01:01<00:26,  3.06it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  69%|██████▉   | 177/256.0 [01:02<00:26,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  70%|██████▉   | 178/256.0 [01:02<00:25,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  70%|██████▉   | 179/256.0 [01:02<00:25,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  70%|███████   | 180/256.0 [01:03<00:24,  3.05it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  71%|███████   | 181/256.0 [01:03<00:24,  3.07it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  71%|███████   | 182/256.0 [01:03<00:24,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  71%|███████▏  | 183/256.0 [01:04<00:24,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  72%|███████▏  | 184/256.0 [01:04<00:23,  3.00it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  72%|███████▏  | 185/256.0 [01:04<00:24,  2.95it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  73%|███████▎  | 186/256.0 [01:05<00:23,  2.93it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  73%|███████▎  | 187/256.0 [01:05<00:22,  3.05it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  73%|███████▎  | 188/256.0 [01:05<00:22,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  74%|███████▍  | 189/256.0 [01:06<00:22,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  74%|███████▍  | 190/256.0 [01:06<00:22,  2.96it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  75%|███████▍  | 191/256.0 [01:06<00:21,  2.99it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  75%|███████▌  | 192/256.0 [01:07<00:21,  2.99it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  75%|███████▌  | 193/256.0 [01:07<00:21,  2.98it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  76%|███████▌  | 194/256.0 [01:07<00:20,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  76%|███████▌  | 195/256.0 [01:08<00:20,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  77%|███████▋  | 196/256.0 [01:08<00:19,  3.01it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  77%|███████▋  | 197/256.0 [01:08<00:19,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  77%|███████▋  | 198/256.0 [01:09<00:19,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  78%|███████▊  | 199/256.0 [01:09<00:18,  3.15it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  78%|███████▊  | 200/256.0 [01:09<00:17,  3.14it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  79%|███████▊  | 201/256.0 [01:10<00:17,  3.10it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  79%|███████▉  | 202/256.0 [01:10<00:17,  3.09it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  79%|███████▉  | 203/256.0 [01:10<00:17,  3.08it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  80%|███████▉  | 204/256.0 [01:11<00:16,  3.06it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  80%|████████  | 205/256.0 [01:11<00:16,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  80%|████████  | 206/256.0 [01:11<00:16,  3.07it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  81%|████████  | 207/256.0 [01:12<00:15,  3.07it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  81%|████████▏ | 208/256.0 [01:12<00:15,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  82%|████████▏ | 209/256.0 [01:12<00:15,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  82%|████████▏ | 210/256.0 [01:13<00:15,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  82%|████████▏ | 211/256.0 [01:13<00:14,  3.12it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  83%|████████▎ | 212/256.0 [01:13<00:14,  3.10it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  83%|████████▎ | 213/256.0 [01:13<00:13,  3.11it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  84%|████████▎ | 214/256.0 [01:14<00:13,  3.11it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  84%|████████▍ | 215/256.0 [01:14<00:13,  3.11it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  84%|████████▍ | 216/256.0 [01:14<00:12,  3.11it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  85%|████████▍ | 217/256.0 [01:15<00:12,  3.06it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  85%|████████▌ | 218/256.0 [01:15<00:12,  3.05it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  86%|████████▌ | 219/256.0 [01:15<00:12,  3.00it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  86%|████████▌ | 220/256.0 [01:16<00:11,  3.03it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  86%|████████▋ | 221/256.0 [01:16<00:11,  3.04it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  87%|████████▋ | 222/256.0 [01:16<00:11,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  87%|████████▋ | 223/256.0 [01:17<00:10,  3.13it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  88%|████████▊ | 224/256.0 [01:17<00:10,  3.14it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  88%|████████▊ | 225/256.0 [01:17<00:10,  3.10it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  88%|████████▊ | 226/256.0 [01:18<00:09,  3.11it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  89%|████████▊ | 227/256.0 [01:18<00:09,  3.07it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  89%|████████▉ | 228/256.0 [01:18<00:09,  3.06it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  89%|████████▉ | 229/256.0 [01:19<00:08,  3.09it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  90%|████████▉ | 230/256.0 [01:19<00:08,  3.08it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  90%|█████████ | 231/256.0 [01:19<00:08,  2.82it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  91%|█████████ | 232/256.0 [01:20<00:08,  2.91it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  91%|█████████ | 233/256.0 [01:20<00:07,  2.97it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  91%|█████████▏| 234/256.0 [01:20<00:07,  3.02it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  92%|█████████▏| 235/256.0 [01:21<00:06,  3.17it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  92%|█████████▏| 236/256.0 [01:21<00:06,  3.16it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  93%|█████████▎| 237/256.0 [01:21<00:05,  3.18it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  93%|█████████▎| 238/256.0 [01:22<00:05,  3.16it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  93%|█████████▎| 239/256.0 [01:22<00:06,  2.71it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  94%|█████████▍| 240/256.0 [01:22<00:05,  2.80it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  94%|█████████▍| 241/256.0 [01:23<00:05,  2.91it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  95%|█████████▍| 242/256.0 [01:23<00:04,  3.00it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  95%|█████████▍| 243/256.0 [01:23<00:04,  3.09it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  95%|█████████▌| 244/256.0 [01:24<00:03,  3.14it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  96%|█████████▌| 245/256.0 [01:24<00:03,  3.11it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  96%|█████████▌| 246/256.0 [01:24<00:03,  3.05it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  96%|█████████▋| 247/256.0 [01:25<00:02,  3.18it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  97%|█████████▋| 248/256.0 [01:25<00:02,  3.16it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  97%|█████████▋| 249/256.0 [01:25<00:02,  3.15it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  98%|█████████▊| 250/256.0 [01:26<00:01,  3.12it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  98%|█████████▊| 251/256.0 [01:26<00:01,  2.99it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  98%|█████████▊| 252/256.0 [01:26<00:01,  2.98it/s]dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  99%|█████████▉| 253/256.0 [01:27<00:00,  3.01it/s]dlrm_main/0 [0]:Training:  GPU memory allocated: 1.07 GB, GPU memory reserved: 5.47 GB, CPU memory usage: 66.83 GB
dlrm_main/0 [0]:CUDA->CPU BWD 2393.9028016532566 MB/s 6362.529408 M elem
dlrm_main/0 [0]:cuda_to_cpu_elapse 10.63122429800569 sec
dlrm_main/0 [0]:CPU->CUDA BWD 19464.236653503747 MB/s 6382.753536 M elem
dlrm_main/0 [0]:cpu_to_cuda_elpase 1.3116884365153965 sec
dlrm_main/0 [0]:1_unique_indices: 0.11956417598412372
dlrm_main/0 [0]:2_cpu_row_idx: 0.25000377316609956
dlrm_main/0 [0]:3_1_0_backup_freqs: 0.6005752698110882
dlrm_main/0 [0]:3_1_1_find_evict_gpu_idxs_elapsed: 0.06153049800195731
dlrm_main/0 [0]:3_1_2_find_evict_index_copy: 0.007793173921527341
dlrm_main/0 [0]:3_1_evict_prepare: 0.9097813940315973
dlrm_main/0 [0]:3_2_1_evict_out_index_select: 0.09256227896548808
dlrm_main/0 [0]:3_2_2_evict_out_gpu_to_cpu_copy: 10.63122429800569
dlrm_main/0 [0]:3_2_2_evict_out_index_select: 2.236044615827268
dlrm_main/0 [0]:3_2_evict_out_elapse: 12.986969341844087
dlrm_main/0 [0]:3_3_non_zero: 0.03436281092581339
dlrm_main/0 [0]:3_4_1_evict_in_index_select: 3.6615651700703893
dlrm_main/0 [0]:3_4_2_evict_in_gpu_to_cpu_copy: 1.3116884365153965
dlrm_main/0 [0]:3_4_3_evict_in_index_copy: 0.05077693788916804
dlrm_main/0 [0]:3_4_evict_in_elapse: 5.031215511873597
dlrm_main/0 [0]:3_5_evict_in_elapse_final: 0.021595980128040537
dlrm_main/0 [0]:3_prepare_rows_on_cuda: 20.409188374556834
dlrm_main/0 [0]:4_cpu_to_gpu_row_idxs: 0.05519434507004917
dlrm_main/0 [0]:
dlrm_main/0 [0]:Epoch 0:  99%|█████████▉| 254/256.0 [01:27<00:00,  3.05it/s]
dlrm_main/0 [0]:Epoch 0:  99%|█████████▉| 254/256.0 [01:27<00:00,  2.90it/s]
torchx 2022-09-30 14:35:54 INFO     Job finished: SUCCEEDED
local_cwd://torchx/dlrm_main-z46vjbk1kts1bd
